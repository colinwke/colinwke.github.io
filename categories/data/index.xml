<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>data | 分类 | Alphaks</title>
        <link>https://example.com/categories/data.html</link>
        <description>data | 分类 | Alphaks</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>wangkest@qq.com (Alphaks)</managingEditor>
            <webMaster>wangkest@qq.com (Alphaks)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 27 Apr 2023 10:38:16 &#43;0800</lastBuildDate><atom:link href="https://example.com/categories/data.html" rel="self" type="application/rss+xml" /><item>
    <title>save DataFrame as partition of hive table</title>
    <link>https://example.com/posts/2304271038-dataframe-create-hive-table.html</link>
    <pubDate>Thu, 27 Apr 2023 10:38:16 &#43;0800</pubDate>
    <author>wangke</author>
    <guid>https://example.com/posts/2304271038-dataframe-create-hive-table.html</guid>
    <description><![CDATA[使用DataFrame直接创建hive表, 并作为其中的一个分区数据 test 1 1 2 3 4 5 6 table .write .format(&#34;hive&#34;) .mode(&#34;overwrite&#34;) .option(&#34;path&#34;, inputPath + &#34;_table&#34;) .insertInto(tableName) error, 需要先创建表 1 Exception in thread &#34;main&#34; org.apache.spark.sql.AnalysisException: Table not found: hdp_lbg_ectech_ads.zp_compensate_ad_detail_test1; test 2 首]]></description>
</item>
</channel>
</rss>
